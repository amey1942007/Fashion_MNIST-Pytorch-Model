{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNls43IvDu4PEIgNRt7/2xD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amey1942007/Fashion_MNIST-Pytorch-Model/blob/main/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#========================================================================================================================================================== Import required Module and Library =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "rQ8H4rMpCtAO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "eLx3t0Phg--u"
      },
      "outputs": [],
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "\n",
        "# Datasets of Fashion MNIST\n",
        "from torchvision import datasets\n",
        "\n",
        "# import dataloader which creates an iterable around the dataset of 60,000 training and 10,000 testing data\n",
        "from torch.utils.data import dataloader\n",
        "\n",
        "#import pytorch neural network module for making custom layers\n",
        "from torch import nn\n",
        "\n",
        "# import a converter which converts the object into tensor (image---> tensor)\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# data manupulating tools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Randomization library\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training data checks =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "vQi82_pQhmI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing data\n",
        "train = datasets.FashionMNIST(root='data',train=True,download=True,transform=ToTensor())\n"
      ],
      "metadata": {
        "id": "q-ZTH1vthwfY"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data\n",
        "train #60,000 samples for training\n",
        "train.data.shape #is a tensor of (60000,28,28) # an image of 28*28 pixel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D08KJRRehk7m",
        "outputId": "a6e80af1-7f4c-46db-bdbf-d003eb4cdd7b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test data checks =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "tKs9Z82ZCoXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the test data\n",
        "test = datasets.FashionMNIST(root='data',train=False,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "id": "M7CtQV0AiQUa"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data\n",
        "test.data.shape # shows a tensor of (10000,28,28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcmnJG6niX8R",
        "outputId": "113a747a-cda1-4ec5-bc18-1afa92474888"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader checks =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "4_-joTRTikpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dta into batches of 100\n",
        "train_dataloader = dataloader.DataLoader(dataset=train,batch_size=100)\n",
        "test_dataloader = dataloader.DataLoader(dataset=test,batch_size=100)"
      ],
      "metadata": {
        "id": "p-isjTGTihpa"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataloader) # shows that we have sucess created a batch of 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntvZQrHYi5eu",
        "outputId": "e32ab6e4-8b61-4da4-9035-2f2c85d4ee49"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model construction =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "VZyxAfpYryWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# here we will create the neural network\n",
        "class NeuralNetwork(nn.Module): # this nn.Module inherites the property of its super class by calling super().__Init__()\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__() # as discussed earlier is  used for inheritance\n",
        "\n",
        "    self.flatten = nn.Flatten() # Flattens\n",
        "\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(in_features=784,out_features=512), # applies the linear transformationa and creates the first layer\n",
        "\n",
        "        nn.ReLU(), # applies the rectified linear Unit to the output of the first layer to make the output in 0-1 range\n",
        "\n",
        "        nn.Linear(in_features=512,out_features=512), # applies the linear transformationa and creates the second layer\n",
        "\n",
        "        nn.ReLU(), # applies the rectified linear Unit to the output of the second layer to make the output in 0-1 range\n",
        "\n",
        "        nn.Linear(in_features=512,out_features=10), # finally applies a linear transformation and predicts the category of clothes\n",
        "        )\n",
        "\n",
        "  def forward(self,x):\n",
        "    flatten_input = self.flatten(x)\n",
        "\n",
        "    #appling our neural network to the flatten input\n",
        "    network = self.linear_relu_stack(flatten_input)\n",
        "\n",
        "    return network # return the result\n",
        "\n",
        "model = NeuralNetwork() # create the model"
      ],
      "metadata": {
        "id": "i1q0HbZbjN3O"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "XBmzKej9r0Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss() # we use cross Entropy loss because the output of our network in 10 (multiple)\n",
        "\n",
        "optimiser = torch.optim.SGD(model.parameters(),lr=0.01) # create an optimiser to change the weight and bias and calculate gradient\n"
      ],
      "metadata": {
        "id": "ga20r0-dkims"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function defining =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "_gkBCBTar001"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we define our training and test loops\n",
        "def Training(dataloader,model,loss,optimiser):\n",
        "  model.train() # set the model into training mode\n",
        "\n",
        "  for batch_number , (x,y) in enumerate(dataloader):\n",
        "    y_predicted = model(x) # calculate the predicted answer for the data\n",
        "\n",
        "    l = loss(y_predicted,y) # calculate the loss\n",
        "\n",
        "    optimiser.zero_grad() # set the gradient to zero\n",
        "\n",
        "    l.backward() # calculate the derivative in the the backpropagation\n",
        "\n",
        "    optimiser.step() # change the weight and bias according to the loss and learnig rate\n",
        "\n",
        "    if batch_number%100==0:\n",
        "      print(f'current loss: {l.item():.5f}  , batch number: {batch_number}') # print the status in every 100 batches\n",
        "\n",
        "def Test(dataloader,model,loss):\n",
        "  model.eval() # sets the model to eval and not to update the computational graph\n",
        "\n",
        "  test_loss , correct = 0,0 # make a counter for the correct answer given an wrong answer given\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x,y in dataloader:\n",
        "      y_predicted = model(x)\n",
        "\n",
        "      test_loss += loss(y_predicted,y).item()\n",
        "      correct += (y_predicted.argmax(1)==y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= len(dataloader) # calculate the average loss or wrong answer reported per batch\n",
        "\n",
        "  correct /= 10000 # calculate the accuracy i.e,The amount of correct category guess by the model\n",
        "\n",
        "  print(f'\\n Test Evaluation result: \\n Accuracy: {(correct*100):.2f},\\n Avg loss:{test_loss:.3f}')"
      ],
      "metadata": {
        "id": "K_IQhgJNnGqR"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##         Training and Testing Loop ====================================================================================================================================================="
      ],
      "metadata": {
        "id": "z0u6IV1hr10v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 25 # number of times i want to run\n",
        "for i in range(n_epochs):\n",
        "  print(f\"\\n\\n   Epoch {i+1}  -------------------- \\n\")\n",
        "\n",
        "  Training(train_dataloader,model,loss,optimiser)\n",
        "  Test(test_dataloader,model,loss)\n",
        "print(f\"Done!\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp0yuYTQqALG",
        "outputId": "c34ffadd-040e-4bf7-8ea4-5873d85d939c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "   Epoch 1  -------------------- \n",
            "\n",
            "current loss: 2.30473  , batch number: 0\n",
            "current loss: 2.17090  , batch number: 100\n",
            "current loss: 1.88636  , batch number: 200\n",
            "current loss: 1.40190  , batch number: 300\n",
            "current loss: 1.13488  , batch number: 400\n",
            "current loss: 1.05088  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 65.52,\n",
            " Avg loss:0.958\n",
            "\n",
            "\n",
            "   Epoch 2  -------------------- \n",
            "\n",
            "current loss: 0.93552  , batch number: 0\n",
            "current loss: 0.80976  , batch number: 100\n",
            "current loss: 0.87473  , batch number: 200\n",
            "current loss: 0.74843  , batch number: 300\n",
            "current loss: 0.66688  , batch number: 400\n",
            "current loss: 0.77985  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 73.87,\n",
            " Avg loss:0.726\n",
            "\n",
            "\n",
            "   Epoch 3  -------------------- \n",
            "\n",
            "current loss: 0.63813  , batch number: 0\n",
            "current loss: 0.59879  , batch number: 100\n",
            "current loss: 0.65231  , batch number: 200\n",
            "current loss: 0.65720  , batch number: 300\n",
            "current loss: 0.57501  , batch number: 400\n",
            "current loss: 0.68525  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 77.79,\n",
            " Avg loss:0.631\n",
            "\n",
            "\n",
            "   Epoch 4  -------------------- \n",
            "\n",
            "current loss: 0.51786  , batch number: 0\n",
            "current loss: 0.50710  , batch number: 100\n",
            "current loss: 0.53899  , batch number: 200\n",
            "current loss: 0.61292  , batch number: 300\n",
            "current loss: 0.53512  , batch number: 400\n",
            "current loss: 0.62178  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 79.88,\n",
            " Avg loss:0.577\n",
            "\n",
            "\n",
            "   Epoch 5  -------------------- \n",
            "\n",
            "current loss: 0.45002  , batch number: 0\n",
            "current loss: 0.45405  , batch number: 100\n",
            "current loss: 0.47824  , batch number: 200\n",
            "current loss: 0.58630  , batch number: 300\n",
            "current loss: 0.51572  , batch number: 400\n",
            "current loss: 0.57848  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 81.01,\n",
            " Avg loss:0.543\n",
            "\n",
            "\n",
            "   Epoch 6  -------------------- \n",
            "\n",
            "current loss: 0.40554  , batch number: 0\n",
            "current loss: 0.41881  , batch number: 100\n",
            "current loss: 0.44105  , batch number: 200\n",
            "current loss: 0.56894  , batch number: 300\n",
            "current loss: 0.50543  , batch number: 400\n",
            "current loss: 0.54927  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 81.56,\n",
            " Avg loss:0.520\n",
            "\n",
            "\n",
            "   Epoch 7  -------------------- \n",
            "\n",
            "current loss: 0.37368  , batch number: 0\n",
            "current loss: 0.39432  , batch number: 100\n",
            "current loss: 0.41570  , batch number: 200\n",
            "current loss: 0.55544  , batch number: 300\n",
            "current loss: 0.49924  , batch number: 400\n",
            "current loss: 0.52954  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 82.13,\n",
            " Avg loss:0.504\n",
            "\n",
            "\n",
            "   Epoch 8  -------------------- \n",
            "\n",
            "current loss: 0.34952  , batch number: 0\n",
            "current loss: 0.37707  , batch number: 100\n",
            "current loss: 0.39722  , batch number: 200\n",
            "current loss: 0.54371  , batch number: 300\n",
            "current loss: 0.49561  , batch number: 400\n",
            "current loss: 0.51698  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 82.64,\n",
            " Avg loss:0.492\n",
            "\n",
            "\n",
            "   Epoch 9  -------------------- \n",
            "\n",
            "current loss: 0.33007  , batch number: 0\n",
            "current loss: 0.36463  , batch number: 100\n",
            "current loss: 0.38292  , batch number: 200\n",
            "current loss: 0.53260  , batch number: 300\n",
            "current loss: 0.49291  , batch number: 400\n",
            "current loss: 0.50847  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 82.91,\n",
            " Avg loss:0.482\n",
            "\n",
            "\n",
            "   Epoch 10  -------------------- \n",
            "\n",
            "current loss: 0.31454  , batch number: 0\n",
            "current loss: 0.35530  , batch number: 100\n",
            "current loss: 0.37077  , batch number: 200\n",
            "current loss: 0.52220  , batch number: 300\n",
            "current loss: 0.49042  , batch number: 400\n",
            "current loss: 0.50217  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 83.11,\n",
            " Avg loss:0.473\n",
            "\n",
            "\n",
            "   Epoch 11  -------------------- \n",
            "\n",
            "current loss: 0.30180  , batch number: 0\n",
            "current loss: 0.34750  , batch number: 100\n",
            "current loss: 0.36053  , batch number: 200\n",
            "current loss: 0.51247  , batch number: 300\n",
            "current loss: 0.48890  , batch number: 400\n",
            "current loss: 0.49806  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 83.42,\n",
            " Avg loss:0.466\n",
            "\n",
            "\n",
            "   Epoch 12  -------------------- \n",
            "\n",
            "current loss: 0.29122  , batch number: 0\n",
            "current loss: 0.34114  , batch number: 100\n",
            "current loss: 0.35172  , batch number: 200\n",
            "current loss: 0.50378  , batch number: 300\n",
            "current loss: 0.48771  , batch number: 400\n",
            "current loss: 0.49457  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 83.70,\n",
            " Avg loss:0.460\n",
            "\n",
            "\n",
            "   Epoch 13  -------------------- \n",
            "\n",
            "current loss: 0.28274  , batch number: 0\n",
            "current loss: 0.33552  , batch number: 100\n",
            "current loss: 0.34454  , batch number: 200\n",
            "current loss: 0.49526  , batch number: 300\n",
            "current loss: 0.48637  , batch number: 400\n",
            "current loss: 0.49140  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 83.97,\n",
            " Avg loss:0.454\n",
            "\n",
            "\n",
            "   Epoch 14  -------------------- \n",
            "\n",
            "current loss: 0.27586  , batch number: 0\n",
            "current loss: 0.33023  , batch number: 100\n",
            "current loss: 0.33801  , batch number: 200\n",
            "current loss: 0.48727  , batch number: 300\n",
            "current loss: 0.48507  , batch number: 400\n",
            "current loss: 0.48808  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 84.12,\n",
            " Avg loss:0.449\n",
            "\n",
            "\n",
            "   Epoch 15  -------------------- \n",
            "\n",
            "current loss: 0.27036  , batch number: 0\n",
            "current loss: 0.32540  , batch number: 100\n",
            "current loss: 0.33188  , batch number: 200\n",
            "current loss: 0.47894  , batch number: 300\n",
            "current loss: 0.48384  , batch number: 400\n",
            "current loss: 0.48426  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 84.25,\n",
            " Avg loss:0.444\n",
            "\n",
            "\n",
            "   Epoch 16  -------------------- \n",
            "\n",
            "current loss: 0.26560  , batch number: 0\n",
            "current loss: 0.32086  , batch number: 100\n",
            "current loss: 0.32648  , batch number: 200\n",
            "current loss: 0.47104  , batch number: 300\n",
            "current loss: 0.48235  , batch number: 400\n",
            "current loss: 0.48055  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 84.48,\n",
            " Avg loss:0.439\n",
            "\n",
            "\n",
            "   Epoch 17  -------------------- \n",
            "\n",
            "current loss: 0.26155  , batch number: 0\n",
            "current loss: 0.31725  , batch number: 100\n",
            "current loss: 0.32181  , batch number: 200\n",
            "current loss: 0.46326  , batch number: 300\n",
            "current loss: 0.48047  , batch number: 400\n",
            "current loss: 0.47714  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 84.67,\n",
            " Avg loss:0.434\n",
            "\n",
            "\n",
            "   Epoch 18  -------------------- \n",
            "\n",
            "current loss: 0.25819  , batch number: 0\n",
            "current loss: 0.31359  , batch number: 100\n",
            "current loss: 0.31779  , batch number: 200\n",
            "current loss: 0.45529  , batch number: 300\n",
            "current loss: 0.47900  , batch number: 400\n",
            "current loss: 0.47361  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 84.82,\n",
            " Avg loss:0.430\n",
            "\n",
            "\n",
            "   Epoch 19  -------------------- \n",
            "\n",
            "current loss: 0.25472  , batch number: 0\n",
            "current loss: 0.31017  , batch number: 100\n",
            "current loss: 0.31425  , batch number: 200\n",
            "current loss: 0.44781  , batch number: 300\n",
            "current loss: 0.47785  , batch number: 400\n",
            "current loss: 0.46850  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 84.94,\n",
            " Avg loss:0.426\n",
            "\n",
            "\n",
            "   Epoch 20  -------------------- \n",
            "\n",
            "current loss: 0.25155  , batch number: 0\n",
            "current loss: 0.30728  , batch number: 100\n",
            "current loss: 0.31065  , batch number: 200\n",
            "current loss: 0.44053  , batch number: 300\n",
            "current loss: 0.47677  , batch number: 400\n",
            "current loss: 0.46499  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 85.10,\n",
            " Avg loss:0.422\n",
            "\n",
            "\n",
            "   Epoch 21  -------------------- \n",
            "\n",
            "current loss: 0.24874  , batch number: 0\n",
            "current loss: 0.30450  , batch number: 100\n",
            "current loss: 0.30710  , batch number: 200\n",
            "current loss: 0.43373  , batch number: 300\n",
            "current loss: 0.47550  , batch number: 400\n",
            "current loss: 0.46168  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 85.19,\n",
            " Avg loss:0.419\n",
            "\n",
            "\n",
            "   Epoch 22  -------------------- \n",
            "\n",
            "current loss: 0.24631  , batch number: 0\n",
            "current loss: 0.30157  , batch number: 100\n",
            "current loss: 0.30437  , batch number: 200\n",
            "current loss: 0.42733  , batch number: 300\n",
            "current loss: 0.47395  , batch number: 400\n",
            "current loss: 0.45801  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 85.27,\n",
            " Avg loss:0.415\n",
            "\n",
            "\n",
            "   Epoch 23  -------------------- \n",
            "\n",
            "current loss: 0.24405  , batch number: 0\n",
            "current loss: 0.29856  , batch number: 100\n",
            "current loss: 0.30105  , batch number: 200\n",
            "current loss: 0.42141  , batch number: 300\n",
            "current loss: 0.47308  , batch number: 400\n",
            "current loss: 0.45466  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 85.33,\n",
            " Avg loss:0.412\n",
            "\n",
            "\n",
            "   Epoch 24  -------------------- \n",
            "\n",
            "current loss: 0.24124  , batch number: 0\n",
            "current loss: 0.29495  , batch number: 100\n",
            "current loss: 0.29840  , batch number: 200\n",
            "current loss: 0.41593  , batch number: 300\n",
            "current loss: 0.47248  , batch number: 400\n",
            "current loss: 0.45134  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 85.35,\n",
            " Avg loss:0.409\n",
            "\n",
            "\n",
            "   Epoch 25  -------------------- \n",
            "\n",
            "current loss: 0.23887  , batch number: 0\n",
            "current loss: 0.29221  , batch number: 100\n",
            "current loss: 0.29608  , batch number: 200\n",
            "current loss: 0.41062  , batch number: 300\n",
            "current loss: 0.47117  , batch number: 400\n",
            "current loss: 0.44800  , batch number: 500\n",
            "\n",
            " Test Evaluation result: \n",
            " Accuracy: 85.53,\n",
            " Avg loss:0.406\n",
            "Done!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization =========================================================================================================================================================="
      ],
      "metadata": {
        "id": "Zll6Rmobr2uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "# Get a single random index\n",
        "random_idx = random.randint(0, 9999)\n",
        "\n",
        "# Display the image from the chosen random index\n",
        "plt.imshow(test.data[random_idx], cmap = \"Greys\")\n",
        "\n",
        "# Get the pixel data (x) from the same random index\n",
        "x = test[random_idx][0]\n",
        "\n",
        "# Get the true / correct label (y) from the same random index\n",
        "y = test[random_idx][1]\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model(x)                     # predict with model\n",
        "    prediction = labels[pred[0].argmax(0)] # find predicted label\n",
        "    truth      = labels[y]                 # true label\n",
        "\n",
        "    print(f\"simpleNN predict as {prediction} ; truth is {truth}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "POLW1q_Yr_ap",
        "outputId": "c0f63b66-cff0-4fe8-8a48-b7eb575a95f3"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simpleNN predict as Sneaker ; truth is Sneaker\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72e987d4"
      },
      "source": [
        "## Saving the model's state dict =========================================================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "897c8808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74253a02-7396-4051-80df-0e4851da82db"
      },
      "source": [
        "\n",
        "# Define the path where you want to save the model's state_dict\n",
        "model_save_path = \"fashion_mnist_model_weights.pth\"\n",
        "\n",
        "# Save the model's state_dict\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model weights saved to {model_save_path}\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to fashion_mnist_model_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07bbe9da"
      },
      "source": [
        "To load the saved weights,we first need to re-instantiate your model architecture, and then load the state dict into it. You should always load weights into a model that has the *same architecture* as the one that was saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bc800a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edad4e39-0db7-4764-ae0f-d5b8918fc35d"
      },
      "source": [
        "# First, create a new instance of your NeuralNetwork model\n",
        "loaded_model = NeuralNetwork()\n",
        "\n",
        "# Load the saved state_dict into the new model instance\n",
        "loaded_model.load_state_dict(torch.load(\"fashion_mnist_model_weights.pth\"))\n",
        "\n",
        "# Set the model to evaluation mode if you're not planning to train it further\n",
        "loaded_model.eval()\n",
        "\n",
        "print(\"Model weights loaded successfully into 'loaded_model'.\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights loaded successfully into 'loaded_model'.\n"
          ]
        }
      ]
    }
  ]
}